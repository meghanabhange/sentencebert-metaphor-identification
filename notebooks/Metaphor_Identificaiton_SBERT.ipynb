{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mn0cPtaTj6KI"
   },
   "outputs": [],
   "source": [
    "# !pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QnBiT8gIkEGr"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import (\n",
    "    InputExample,\n",
    "    LoggingHandler,\n",
    "    SentenceTransformer,\n",
    "    evaluation,\n",
    "    losses,\n",
    "    models,\n",
    "    util,\n",
    ")\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9BWmzYq_NwO"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('bert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQ9uzDY0nB8H"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vuamc.csv\")\n",
    "\n",
    "\n",
    "def preprocess(df):\n",
    "    train = df[df[\"partition\"] == \"train\"]\n",
    "    train, dev = train_test_split(train, test_size=0.33, random_state=42)\n",
    "    test = df[df[\"partition\"] == \"test\"]\n",
    "    train = train[[\"sentence\", \"verb\", \"y\"]]\n",
    "    test = test[[\"sentence\", \"verb\", \"y\"]]\n",
    "    return train, test, dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt9AgQO4oCov"
   },
   "outputs": [],
   "source": [
    "def create_training_sample(train, test, dev):\n",
    "    pooling_model = models.Pooling(\n",
    "        word_embedding_model.get_word_embedding_dimension(),\n",
    "        pooling_mode_mean_tokens=True,\n",
    "        pooling_mode_cls_token=False,\n",
    "        pooling_mode_max_tokens=False,\n",
    "    )\n",
    "    train_samples = []\n",
    "    for index, row in train.iterrows():\n",
    "        train_samples.append(\n",
    "            InputExample(texts=[row[\"sentence\"], row[\"verb\"]], label=row[\"y\"])\n",
    "        )\n",
    "    train_dataloader = DataLoader(\n",
    "        train_samples, shuffle=True, batch_size=train_batch_size\n",
    "    )\n",
    "    train_loss = losses.OnlineContrastiveLoss(\n",
    "        model=model, distance_metric=distance_metric, margin=margin\n",
    "    )\n",
    "    dev_sentences1 = []\n",
    "    dev_sentences2 = []\n",
    "    dev_labels = []\n",
    "    for index, row in dev.iterrows():\n",
    "        dev_sentences1.append(row[\"sentence\"])\n",
    "        dev_sentences2.append(row[\"verb\"])\n",
    "        dev_labels.append(int(row[\"y\"]))\n",
    "\n",
    "    evaluators = []\n",
    "\n",
    "    evaluators.append(\n",
    "        evaluation.BinaryClassificationEvaluator(\n",
    "            dev_sentences1, dev_sentences2, dev_labels\n",
    "        )\n",
    "    )\n",
    "    evaluators.append(\n",
    "        evaluation.EmbeddingSimilarityEvaluator(\n",
    "            dev_sentences1, dev_sentences2, dev_labels\n",
    "        )\n",
    "    )\n",
    "    dev_evaluator = evaluation.SequentialEvaluator(\n",
    "        evaluators, main_score_function=lambda scores: scores[-1]\n",
    "    )\n",
    "    return train_dataloader, train_loss, dev_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wc4z6cRsE4ZZ"
   },
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"  #'xlm-roberta-base'\n",
    "train_batch_size = 16\n",
    "model_save_path = \"output/metaphor\"\n",
    "word_embedding_model = models.Transformer(model_name)\n",
    "distance_metric = losses.SiameseDistanceMetric.COSINE_DISTANCE\n",
    "margin = 0.5\n",
    "\n",
    "train, test, dev = preprocess(df)\n",
    "train_dataloader, train_loss, dev_evaluator = create_training_sample(train, test, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAYIzxWcqlau"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "warmup_steps = math.ceil(\n",
    "    len(train_dataloader) * num_epochs * 0.1\n",
    ")  # 10% of train data for warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EBMiVIr_squr"
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=dev_evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=model_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqkEXr994Pb2"
   },
   "outputs": [],
   "source": [
    "all_genre = [\"news\", \"fiction\", \"academic\", \"conversation\"]\n",
    "test = df[df[\"partition\"] == \"test\"]\n",
    "for genre in all_genre:\n",
    "    test_samples = []\n",
    "    genre_test = test[test[\"genre\"] == genre]\n",
    "    for index, row in genre_test.iterrows():\n",
    "        test_samples.append(\n",
    "            InputExample(texts=[row[\"sentence\"], row[\"verb\"]], label=row[\"y\"])\n",
    "        )\n",
    "    model = SentenceTransformer(model_save_path)\n",
    "    test_evaluator = evaluation.BinaryClassificationEvaluator.from_input_examples(\n",
    "        test_samples, batch_size=train_batch_size, name=\"metaphor-test\"\n",
    "    )\n",
    "    score = test_evaluator(model, output_path=model_save_path)\n",
    "    print(f\"Genre : {genre}\\tScore : {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27CbeYIeZ2Sc"
   },
   "outputs": [],
   "source": [
    "# Genre : news\tScore : 0.7593295445439239\n",
    "# Genre : fiction\tScore : 0.583352792743637\n",
    "# Genre : academic\tScore : 0.8010891703480427\n",
    "# Genre : conversation\tScore : 0.4309286215122053"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Metaphor-Identificaiton-SBERT.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
